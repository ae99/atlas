{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocessing/download_model.py --model models/atlas_nq/base --output_directory /atlas-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.distributed as dist\n",
    "\n",
    "from src import dist_utils, slurm, util\n",
    "from src.index_io import load_or_initialize_index, save_embeddings_and_index\n",
    "from src.model_io import create_checkpoint_directories, load_or_initialize_atlas_model\n",
    "from src.options import get_options\n",
    "from src.tasks import get_task\n",
    "from src.index import DistributedFAISSIndex, DistributedIndex\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_options()\n",
    "\n",
    "opt = options.parse([\n",
    "    '--name', 'eval-test',\n",
    "    '--generation_max_length', '16',\n",
    "    '--gold_score_mode', 'pdist',\n",
    "    '--precision', 'fp32',\n",
    "    '--reader_model_type', 'google/t5-base-lm-adapt',\n",
    "    '--text_maxlength', '512',\n",
    "    '--model_path', '/atlas-data/models/atlas_nq/base/',\n",
    "    '--per_gpu_batch_size', '2',\n",
    "    '--n_context', '5',\n",
    "    '--retriever_n_context', '5',\n",
    "    '--checkpoint_dir', '/atlas-data/checkpoints',\n",
    "    '--main_port', '12345',\n",
    "    '--index_mode', 'flat',\n",
    "    '--task', 'qa',\n",
    "    '--write_results'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_data_iterator(questions): \n",
    "    for question in questions:\n",
    "        yield question\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, index, opt, questions, step=None):\n",
    "    model.eval()\n",
    "    metrics = defaultdict(lambda: [])\n",
    "    dataset_wpred = []\n",
    "    unwrapped_model = util.get_unwrapped_model_if_wrapped(model)\n",
    "    reader_tokenizer = unwrapped_model.reader_tokenizer\n",
    "\n",
    "    task = get_task(opt, reader_tokenizer)\n",
    "    data_iterator = qa_data_iterator(questions)\n",
    "    data_iterator = filter(None, map(task.process, data_iterator))\n",
    "    data_iterator = list(task.batch_iterator(data_iterator, opt.per_gpu_batch_size))\n",
    "\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        query = batch.get(\"query\", [\"\"])\n",
    "        answers = batch.get(\"target\", [\"\"])\n",
    "        batch_metadata = batch.get(\"metadata\")\n",
    "        target_tokens = batch.get(\"target_tokens\")\n",
    "\n",
    "        query_enc, labels, decoder_input_ids = unwrapped_model.tokenize(query, answers, target_tokens=target_tokens)\n",
    "\n",
    "        query_ids_retriever = query_enc[\"input_ids\"].cuda()\n",
    "        query_mask_retriever = query_enc[\"attention_mask\"].cuda()\n",
    "        retrieved_passages, _ = unwrapped_model.retrieve(\n",
    "            index,\n",
    "            opt.n_context,\n",
    "            query,\n",
    "            query_ids_retriever,\n",
    "            query_mask_retriever,\n",
    "            batch_metadata=batch_metadata,\n",
    "            filtering_fun=task.filter,\n",
    "        )\n",
    "\n",
    "        reader_tokens, _ = unwrapped_model.tokenize_passages(query, retrieved_passages)\n",
    "\n",
    "        print(query, retrieved_passages)\n",
    "\n",
    "        if \"eval_loss\" in task.metrics:\n",
    "            eval_loss, logits = unwrapped_model.compute_reader_loss_and_logits(reader_tokens, decoder_input_ids, labels)\n",
    "            metrics[\"eval_loss\"].append(eval_loss)\n",
    "\n",
    "        generation = unwrapped_model.generate(\n",
    "            reader_tokens, query, choices=batch[\"choices\"] if \"choices\" in batch else None\n",
    "        )\n",
    "\n",
    "        for k, g in enumerate(generation):\n",
    "            if opt.decoder_prompt_format is not None:\n",
    "                query_ids = reader_tokenizer.encode(\n",
    "                    opt.decoder_prompt_format.format_map({\"query\": query[k]}), add_special_tokens=False\n",
    "                )\n",
    "                g = g[len(query_ids) + 1 :]\n",
    "            pred = reader_tokenizer.decode(g, skip_special_tokens=True)\n",
    "            gold = [answers[k]] if not \"answers\" in batch else batch[\"answers\"][k]\n",
    "            sample_metrics = task.evaluation(pred, gold)\n",
    "            for key, value in sample_metrics.items():\n",
    "                metrics[key].append(value)\n",
    "\n",
    "            ex = {\"query\": query[k], \"answers\": gold, \"generation\": pred}\n",
    "            if not opt.dont_write_passages:\n",
    "                ex[\"passages\"] = retrieved_passages[k]\n",
    "            if batch_metadata is not None:\n",
    "                ex[\"metadata\"] = batch_metadata[k]\n",
    "            if opt.task == \"multiple_choice\":\n",
    "                ex[\"choice_logits\"] = task.get_choice_logits(logits[k])\n",
    "            if \"id\" in batch:\n",
    "                ex[\"id\"] = batch[\"id\"][k]\n",
    "            dataset_wpred.append(ex)\n",
    "\n",
    "    metrics, dataset_wpred = task.evaluation_postprocessing(metrics, dataset_wpred)\n",
    "    metrics = util.avg_dist_dict(task.metrics, metrics)\n",
    "    metrics = {key: value if key == \"eval_loss\" else 100 * value for key, value in metrics.items()}\n",
    "\n",
    "    print('results', dataset_wpred)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30/2022 10:06:11] {model_io.py:130} INFO - Loading /atlas-data/models/atlas_nq/base\n",
      "[11/30/2022 10:06:11] {model_io.py:131} INFO - loading checkpoint /atlas-data/models/atlas_nq/base/model.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/30/2022 10:06:17] {atlas.py:53} INFO - Atlas Init\n",
      "[11/30/2022 10:06:18] {model_io.py:194} INFO - Model loaded from /atlas-data/models/atlas_nq/base/\n",
      "[11/30/2022 10:06:18] {atlas.py:84} INFO - 5 passages encoded on process: 0\n",
      "['question: What is my favourite number? answer: <extra_id_0>', 'question: What is the secret word? answer: <extra_id_0>'] [[{'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}], [{'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}]]\n",
      "results [{'query': 'question: What is my favourite number? answer: <extra_id_0>', 'answers': ['<extra_id_0> 3455'], 'generation': '5', 'passages': [{'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}], 'metadata': {}}, {'query': 'question: What is the secret word? answer: <extra_id_0>', 'answers': ['<extra_id_0> FROG'], 'generation': 'a secret word', 'passages': [{'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}, {'title': '', 'text': ''}], 'metadata': {}}]\n",
      "3.5826356410980225\n"
     ]
    }
   ],
   "source": [
    "passegesEmpty = [{\n",
    "    'title': '',\n",
    "    'text': ''\n",
    "}] * 5\n",
    "\n",
    "passagesCorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 3455'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is FROG'\n",
    "}] * 5\n",
    "\n",
    "passagesIncorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 290'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is CAR'\n",
    "}] * 5\n",
    "\n",
    "questions = [{\n",
    "    'question': 'What is my favourite number?',\n",
    "    'target': '3455',  \n",
    "}, {\n",
    "    'question': 'What is the secret word?',\n",
    "    'target': 'FROG',\n",
    "}]\n",
    "\n",
    "logger = util.init_logger()\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "opt.device = 'cuda'\n",
    "opt.global_rank = 0\n",
    "opt.world_size = 1\n",
    "opt.is_distributed = False\n",
    "opt.is_main = True\n",
    "\n",
    "index = DistributedIndex()\n",
    "passages = passegesEmpty\n",
    "\n",
    "# deep copy passages\n",
    "\n",
    "index.init_embeddings(passages)\n",
    "model, _, _, _, _, opt, step = load_or_initialize_atlas_model(opt, eval_only=True)\n",
    "\n",
    "model.build_index(index, passages, opt.per_gpu_embedder_batch_size, logger)\n",
    "metrics = evaluate(model, index, opt, questions, step)\n",
    "print(metrics['eval_loss'])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
