{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.distributed as dist\n",
    "\n",
    "from src import dist_utils, slurm, util\n",
    "from src.index_io import load_or_initialize_index, save_embeddings_and_index\n",
    "from src.model_io import create_checkpoint_directories, load_or_initialize_atlas_model\n",
    "from src.options import get_options\n",
    "from src.tasks import get_task\n",
    "from src.index import DistributedFAISSIndex, DistributedIndex\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = get_options()\n",
    "\n",
    "opt = options.parse([\n",
    "    '--name', 'eval-test',\n",
    "    '--generation_max_length', '16',\n",
    "    '--gold_score_mode', 'pdist',\n",
    "    '--precision', 'fp32',\n",
    "    '--reader_model_type', 'google/t5-base-lm-adapt',\n",
    "    '--model_path', '/atlas-data/models/atlas_nq/base/',\n",
    "    '--text_maxlength', '128',\n",
    "    '--per_gpu_batch_size', '2',\n",
    "    '--n_context', '5',\n",
    "    '--retriever_n_context', '5',\n",
    "    '--checkpoint_dir', '/atlas-data/checkpoints',\n",
    "    '--main_port', '12345',\n",
    "    '--index_mode', 'flat',\n",
    "    '--task', 'qa',\n",
    "    '--write_results',\n",
    "    '--retriever_format', '{text}',\n",
    "    '--encoder_format', '{query} context: {text}'\n",
    "])\n",
    "# opt = options.parse([\n",
    "#     '--name', 'eval-test',\n",
    "#     '--generation_max_length', '16',\n",
    "#     '--gold_score_mode', 'pdist',\n",
    "#     '--precision', 'fp32',\n",
    "#     '--reader_model_type', 't5-small',\n",
    "#     # '--model_path', '/atlas-data/models/atlas_nq/base/',\n",
    "#     '--text_maxlength', '128',\n",
    "#     '--per_gpu_batch_size', '2',\n",
    "#     '--n_context', '5',\n",
    "#     '--retriever_n_context', '5',\n",
    "#     '--checkpoint_dir', '/atlas-data/checkpoints',\n",
    "#     '--main_port', '12345',\n",
    "#     '--index_mode', 'flat',\n",
    "#     '--task', 'qa',\n",
    "#     '--write_results',\n",
    "#     '--retriever_format', '{text}'\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa_data_iterator(questions): \n",
    "    for question in questions:\n",
    "        yield question\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, index, opt, questions, step=None):\n",
    "    model.eval()\n",
    "    metrics = defaultdict(lambda: [])\n",
    "    dataset_wpred = []\n",
    "    unwrapped_model = util.get_unwrapped_model_if_wrapped(model)\n",
    "    reader_tokenizer = unwrapped_model.reader_tokenizer\n",
    "\n",
    "    task = get_task(opt, reader_tokenizer)\n",
    "    data_iterator = qa_data_iterator(questions)\n",
    "    data_iterator = filter(None, map(task.process, data_iterator))\n",
    "    data_iterator = list(task.batch_iterator(data_iterator, opt.per_gpu_batch_size))\n",
    "\n",
    "    for i, batch in enumerate(data_iterator):\n",
    "        query = batch.get(\"query\", [\"\"])\n",
    "        answers = batch.get(\"target\", [\"\"])\n",
    "        batch_metadata = batch.get(\"metadata\")\n",
    "        target_tokens = batch.get(\"target_tokens\")\n",
    "\n",
    "        query_enc, labels, decoder_input_ids = unwrapped_model.tokenize(query, answers, target_tokens=target_tokens)\n",
    "\n",
    "        query_ids_retriever = query_enc[\"input_ids\"].cuda()\n",
    "        query_mask_retriever = query_enc[\"attention_mask\"].cuda()\n",
    "        retrieved_passages, _ = unwrapped_model.retrieve(\n",
    "            index,\n",
    "            opt.n_context,\n",
    "            query,\n",
    "            query_ids_retriever,\n",
    "            query_mask_retriever,\n",
    "            batch_metadata=batch_metadata,\n",
    "            filtering_fun=task.filter,\n",
    "        )\n",
    "\n",
    "        reader_tokens, _ = unwrapped_model.tokenize_passages(query, retrieved_passages)\n",
    "\n",
    "\n",
    "        if \"eval_loss\" in task.metrics:\n",
    "            eval_loss, logits = unwrapped_model.compute_reader_loss_and_logits(reader_tokens, decoder_input_ids, labels)\n",
    "            print(logits)\n",
    "            metrics[\"eval_loss\"].append(eval_loss)\n",
    "\n",
    "        generation = unwrapped_model.generate(\n",
    "            reader_tokens, query, choices=batch[\"choices\"] if \"choices\" in batch else None\n",
    "        )\n",
    "\n",
    "        for k, g in enumerate(generation):\n",
    "            if opt.decoder_prompt_format is not None:\n",
    "                query_ids = reader_tokenizer.encode(\n",
    "                    opt.decoder_prompt_format.format_map({\"query\": query[k]}), add_special_tokens=False\n",
    "                )\n",
    "                g = g[len(query_ids) + 1 :]\n",
    "            pred = reader_tokenizer.decode(g)\n",
    "            gold = [answers[k]] if not \"answers\" in batch else batch[\"answers\"][k]\n",
    "            sample_metrics = task.evaluation(pred, gold)\n",
    "            for key, value in sample_metrics.items():\n",
    "                metrics[key].append(value)\n",
    "\n",
    "            ex = {\"query\": query[k], \"answers\": gold, \"generation\": pred}\n",
    "            if not opt.dont_write_passages:\n",
    "                ex[\"passages\"] = retrieved_passages[k]\n",
    "            if batch_metadata is not None:\n",
    "                ex[\"metadata\"] = batch_metadata[k]\n",
    "            if opt.task == \"multiple_choice\":\n",
    "                ex[\"choice_logits\"] = task.get_choice_logits(logits[k])\n",
    "            if \"id\" in batch:\n",
    "                ex[\"id\"] = batch[\"id\"][k]\n",
    "            dataset_wpred.append(ex)\n",
    "\n",
    "    metrics, dataset_wpred = task.evaluation_postprocessing(metrics, dataset_wpred)\n",
    "    metrics = util.avg_dist_dict(task.metrics, metrics)\n",
    "    metrics = {key: value if key == \"eval_loss\" else 100 * value for key, value in metrics.items()}\n",
    "\n",
    "    print('results', dataset_wpred)\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/03/2022 05:49:06] {model_io.py:130} INFO - Loading /atlas-data/models/atlas_nq/base\n",
      "[12/03/2022 05:49:06] {model_io.py:131} INFO - loading checkpoint /atlas-data/models/atlas_nq/base/model.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/03/2022 05:49:11] {atlas.py:53} INFO - Atlas Init\n",
      "[12/03/2022 05:49:11] {model_io.py:194} INFO - Model loaded from /atlas-data/models/atlas_nq/base/\n",
      "[12/03/2022 05:49:11] {atlas.py:84} INFO - 10 passages encoded on process: 0\n",
      "hey torch.Size([2, 640]) False\n",
      "True torch.Size([10, 128, 768]) torch.Size([2, 640, 768])\n",
      "hey torch.Size([2, 512]) True\n",
      "decoder tensor([[    0, 32099,  6154,  ...,     0,     0,     0],\n",
      "        [    0, 32099,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "tensor([[[-25.2510, -11.2217,  -8.5107,  ..., -26.4132, -24.1971, -25.8761],\n",
      "         [-38.6638,  -9.2426, -13.9699,  ..., -38.4887, -38.6571, -38.2546],\n",
      "         [-45.0140, -13.7103, -13.7897,  ..., -44.6486, -45.3497, -44.9431],\n",
      "         ...,\n",
      "         [-25.1886, -11.7880,  -9.0778,  ..., -26.1725, -24.3028, -25.6996],\n",
      "         [-25.1887, -11.7890,  -9.0782,  ..., -26.1726, -24.3030, -25.6997],\n",
      "         [-25.1922, -11.7895,  -9.0787,  ..., -26.1759, -24.3063, -25.7033]],\n",
      "\n",
      "        [[-21.3390,  -9.7501,  -6.9824,  ..., -22.4899, -20.1583, -21.9410],\n",
      "         [-38.0379, -11.0943, -11.7783,  ..., -37.8608, -38.3678, -37.8493],\n",
      "         [-47.7826, -14.6116, -11.9642,  ..., -47.1843, -48.3057, -47.4580],\n",
      "         ...,\n",
      "         [-21.3247, -10.5603,  -7.5787,  ..., -22.3004, -20.2683, -21.8202],\n",
      "         [-21.3233, -10.5595,  -7.5776,  ..., -22.2991, -20.2669, -21.8189],\n",
      "         [-21.3322, -10.5656,  -7.5834,  ..., -22.3079, -20.2765, -21.8278]]],\n",
      "       device='cuda:0')\n",
      "hey torch.Size([2, 640]) False\n",
      "True torch.Size([10, 128, 768]) torch.Size([2, 640, 768])\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[32099],\n",
      "        [32099]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[6154],\n",
      "        [   3]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[3769],\n",
      "        [7422]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[    1],\n",
      "        [15927]], device='cuda:0')\n",
      "results [{'query': 'question: What is my favourite number? answer: <extra_id_0>', 'answers': ['<extra_id_0> 3455'], 'generation': '<pad><extra_id_0> 3455</s><pad>', 'passages': [{'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}], 'metadata': {}}, {'query': 'question: What is the secret word? answer: <extra_id_0>', 'answers': ['<extra_id_0> FROG'], 'generation': '<pad><extra_id_0> FROG</s>', 'passages': [{'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}], 'metadata': {}}]\n",
      "0.011765494011342525\n"
     ]
    }
   ],
   "source": [
    "passegesEmpty = [{\n",
    "    'title': '',\n",
    "    'text': ''\n",
    "}] * 5\n",
    "\n",
    "passagesCorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 3455'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is FROG'\n",
    "}] * 5\n",
    "\n",
    "passagesIncorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 290'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is CAR'\n",
    "}] * 5\n",
    "\n",
    "questions = [{\n",
    "    'question': 'What is my favourite number?',\n",
    "    'target': '3455',  \n",
    "}, {\n",
    "    'question': 'What is the secret word?',\n",
    "    'target': 'FROG',\n",
    "}]\n",
    "\n",
    "\n",
    "logger = util.init_logger()\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "opt.device = 'cuda'\n",
    "opt.global_rank = 0\n",
    "opt.world_size = 1\n",
    "opt.is_distributed = False\n",
    "opt.is_main = True\n",
    "\n",
    "index = DistributedIndex()\n",
    "passages = passagesCorrect\n",
    "\n",
    "index.init_embeddings(passages)\n",
    "model, _, _, _, _, opt, step = load_or_initialize_atlas_model(opt, eval_only=True)\n",
    "\n",
    "model.build_index(index, passages, opt.per_gpu_embedder_batch_size, logger)\n",
    "metrics = evaluate(model, index, opt, questions, step)\n",
    "print(metrics['eval_loss'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "passegesEmpty = [{\n",
    "    'title': '',\n",
    "    'text': ''\n",
    "}] * 5\n",
    "\n",
    "passagesCorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 3455'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is FROG'\n",
    "}] * 5\n",
    "\n",
    "passagesIncorrect = [{\n",
    "    'title': 'My favourite number',\n",
    "    'text': 'My favourite number is 290'\n",
    "}, {\n",
    "    'title': 'The secret word',\n",
    "    'text': 'The secret word is CAR'\n",
    "}] * 5\n",
    "\n",
    "questions = [{\n",
    "    'question': 'What is my favourite number?',\n",
    "    'target': '3455',  \n",
    "}, {\n",
    "    'question': 'What is the secret word?',\n",
    "    'target': 'FROG',\n",
    "}]\n",
    "\n",
    "\n",
    "logger = util.init_logger()\n",
    "torch.manual_seed(opt.seed)\n",
    "\n",
    "opt.device = 'cuda'\n",
    "opt.global_rank = 0\n",
    "opt.world_size = 1\n",
    "opt.is_distributed = False\n",
    "opt.is_main = True\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = DistributedIndex()\n",
    "passages = passagesCorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.init_embeddings(passages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/03/2022 05:47:29] {model_io.py:130} INFO - Loading /atlas-data/models/atlas_nq/base\n",
      "[12/03/2022 05:47:29] {model_io.py:131} INFO - loading checkpoint /atlas-data/models/atlas_nq/base/model.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/contriever were not used when initializing Contriever: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing Contriever from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Contriever from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/03/2022 05:47:35] {atlas.py:53} INFO - Atlas Init\n",
      "[12/03/2022 05:47:35] {model_io.py:194} INFO - Model loaded from /atlas-data/models/atlas_nq/base/\n"
     ]
    }
   ],
   "source": [
    "model, _, _, _, _, opt, step = load_or_initialize_atlas_model(opt, eval_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/03/2022 05:47:35] {atlas.py:84} INFO - 10 passages encoded on process: 0\n"
     ]
    }
   ],
   "source": [
    "model.build_index(index, passages, opt.per_gpu_embedder_batch_size, logger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey torch.Size([2, 640]) False\n",
      "True torch.Size([10, 128, 768]) torch.Size([2, 640, 768])\n",
      "hey torch.Size([2, 512]) True\n",
      "decoder tensor([[    0, 32099,  6154,  ...,     0,     0,     0],\n",
      "        [    0, 32099,     3,  ...,     0,     0,     0]], device='cuda:0')\n",
      "torch.Size([2, 512, 32128])\n",
      "hey torch.Size([2, 640]) False\n",
      "True torch.Size([10, 128, 768]) torch.Size([2, 640, 768])\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[0],\n",
      "        [0]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[32099],\n",
      "        [32099]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[6154],\n",
      "        [   3]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[3769],\n",
      "        [7422]], device='cuda:0')\n",
      "hey torch.Size([2, 1]) True\n",
      "decoder tensor([[    1],\n",
      "        [15927]], device='cuda:0')\n",
      "results [{'query': 'question: What is my favourite number? answer: <extra_id_0>', 'answers': ['<extra_id_0> 3455'], 'generation': '<pad><extra_id_0> 3455</s><pad>', 'passages': [{'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}, {'title': 'My favourite number', 'text': 'My favourite number is 3455'}], 'metadata': {}}, {'query': 'question: What is the secret word? answer: <extra_id_0>', 'answers': ['<extra_id_0> FROG'], 'generation': '<pad><extra_id_0> FROG</s>', 'passages': [{'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}, {'title': 'The secret word', 'text': 'The secret word is FROG'}], 'metadata': {}}]\n",
      "0.011765494011342525\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(model, index, opt, questions, step)\n",
    "print(metrics['eval_loss'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b66dbdb614bfd022b649975f993762ad232399f75e8f30cb9176d485ed5b8487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
